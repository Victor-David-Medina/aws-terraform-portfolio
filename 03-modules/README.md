# Phase 03: Modules â€” DRY Infrastructure with Reusable Components

> **Problem:** Copy-pasting VPC configs for every environment creates drift and maintenance nightmares. You need one module, multiple deployments.

## What This Deploys

| Resource | Purpose | Monthly Cost |
|----------|---------|-------------|
| `module "vpc_dev"` | Dev VPC (10.0.0.0/16) with public subnet | $0 |
| `module "vpc_prod"` | Prod VPC (10.1.0.0/16) with public subnet | $0 |
| S3 backend | Remote state with encryption and locking | $0 (Free Tier) |

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              main.tf (root)              â”‚
â”‚                                         â”‚
â”‚  module "vpc_dev" â”€â”€â†’ ./modules/vpc     â”‚
â”‚    vpc_cidr = "10.0.0.0/16"            â”‚
â”‚    environment = "dev"                  â”‚
â”‚                                         â”‚
â”‚  module "vpc_prod" â”€â”€â†’ ./modules/vpc    â”‚
â”‚    vpc_cidr = "10.1.0.0/16"            â”‚
â”‚    environment = "prod"                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
        [S3 Remote State]
        encrypted, locked
```

## Key Decisions

- **Module pattern** â€” same VPC code deploys dev and prod with different CIDRs. Change the module once, both environments update
- **`cidrsubnet()` in the module** â€” calculates subnet CIDRs mathematically instead of hardcoding. `cidrsubnet("10.0.0.0/16", 8, 1)` = `10.0.1.0/24`
- **S3 backend with `use_lockfile`** â€” remote state prevents "it works on my machine" and locking prevents two engineers from running `apply` simultaneously
- **Environment tags from variables** â€” every resource knows if it's dev or prod. This drives IAM policies, cost reports, and incident triage

## What I Learned

1. **Modules are functions for infrastructure** â€” inputs (variables), processing (resources), outputs. The same mental model from programming applies. One VPC module, two calls, two completely isolated networks
2. **Remote state is non-negotiable for teams** â€” local `.tfstate` files work solo but break the moment a second person touches the project. S3 + locking is the standard
3. **`cidrsubnet()` eliminates CIDR math errors** â€” instead of manually calculating `10.0.1.0/24`, `10.0.2.0/24`, let Terraform do it. Fewer typos, consistent subnetting across environments

## File Structure

```
03-modules/
â”œâ”€â”€ main.tf              # Root â€” calls vpc module twice (dev + prod)
â”œâ”€â”€ outputs.tf           # Exposes module outputs
â””â”€â”€ modules/
    â””â”€â”€ vpc/
        â””â”€â”€ main.tf      # Reusable VPC: vpc + public subnet + tags
```

## Deploy

```bash
cd 03-modules

# Initialize â€” downloads provider + configures S3 backend
terraform init

# Preview â€” shows dev AND prod VPC resources
terraform plan

# Deploy â€” creates both VPCs in one apply
terraform apply

# Verify both environments exist
terraform output
```

## Cleanup

```bash
terraform destroy
```

> **Note:** Remote state in S3 persists after destroy. The state file records that resources were removed, but the bucket and state file remain for audit history.

---

ðŸ“‚ **Previous:** [02-vpc](../02-vpc) | **Next:** [04-advanced-hcl](../04-advanced-hcl) â€” Workspaces and dynamic configuration
