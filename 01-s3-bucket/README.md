# Phase 01: S3 Bucket â€” Your First Terraform Resource

> **Problem:** You need a centralized, tagged storage bucket managed entirely through code â€” no ClickOps.

## What This Deploys

| Resource | Purpose | Monthly Cost |
|----------|---------|-------------|
| `aws_s3_bucket` | Object storage with environment tagging | $0 (Free Tier) |

## Architecture

```
Terraform CLI
    â†“
  [AWS Provider v5.x]
    â†“
  [S3 Bucket: vdm-dm-terraform]
    â””â”€â”€ Tags: Environment=dev, Project=VDM-Cloud-Ops, ManagedBy=Terraform
```

## Key Decisions

- **Explicit provider version constraint** (`~> 5.0`) â€” prevents breaking changes from unexpected upgrades
- **Consistent tagging** â€” every resource gets `Environment`, `Project`, and `ManagedBy` from day one
- **Single region** (`us-east-1`) â€” cheapest region, keeps costs at $0 for learning

## What I Learned

1. **Terraform init/plan/apply lifecycle** â€” the mental model of "preview before you change anything" comes from the same discipline as double-entry accounting: verify before you commit
2. **Resource tagging as operational hygiene** â€” tags aren't decoration. In production, they drive cost allocation, access policies, and incident triage
3. **Provider versioning matters** â€” pinning `~> 5.0` means "any 5.x but never 6.0." One unversioned `terraform init` in prod can ruin your weekend

## Deploy

```bash
cd 01-s3-bucket

# Initialize â€” downloads the AWS provider
terraform init

# Preview â€” shows exactly what will be created
terraform plan

# Deploy â€” creates the S3 bucket
terraform apply

# Verify in AWS Console or CLI
aws s3 ls | grep vdm
```

## Cleanup

```bash
# Destroy â€” removes the bucket (must be empty)
terraform destroy
```

> **Note:** If the bucket contains objects, empty it first with `aws s3 rm s3://vdm-dm-terraform --recursive` before destroying.

---

ðŸ“‚ **Next:** [02-vpc](../02-vpc) â€” Build the network foundation
